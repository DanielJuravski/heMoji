{
    "he": {
        "title": "<i><b> Heמוג'י</b></i>",
        "sub_title": "מערכת <i><b> Heמוג'י</b></i> הנה מערכת לומדת ומתאימה אימוג׳ים לציוצים וטקסטים קצרים. היכולת הזו שימושית כבסיס למערכות חיזוי סנטימנט, רגש או סרקזם מתוך טקסט.",

        "sb_title": "<i><b> Heמוג'י</b></i>",
        "sb_home_page": "ראשי",
        "sb_about_page": "אודות",

        "text_input": "הכנס/י משפט:",
        "examples_sents": "או בחר/י משפט מהרשימה:",

        "table_label": "אימוג'ים חזויים:",
        "table_emoji": "אימוג'י",
        "table_prob": "הסתברות",

        "page_about_title": "אודות <i><b> Heמוג'י</b></i>:",
        "about01": "מערכת <i><b> Heמוג'י</b></i> חוזה אימוג'ים עבור טקסט עיברי.<p> אנחנו מאמינים שהגיע הזמן לקבל כמה תחזיות אמוג'י על טקסט עברי! מערכת <i><b> Heמוג'י</b></i> חוזה אמוג'ים לטקסטים עבריים, והיא יכולה לשמש כבסיס למערכות גילוי רגשות/רגש/סרקזם יותר ממוקדות.<p>מערכת ה<i><b> Heמוג'י</b></i> היא עיבוד של המערכת האנגלית Felbo et al (2017)<sup>1</sup> לעברית. <p>המערכת פותחה על ידי דניאל ז'ורבסקי במעבדת עיבוד השפה הטבעית בבר אילן, כחלק מפרויקט גדול יותר בנושא ניתוח אוטומטי של טקסט בפגישות פסיכותרפיה, על מנת לקבל תובנות על תהליך הפסיכותרפיה (הפרויקט מפוקח על ידי פרופ' יואב גולדברג מהמחלקה למדעי המחשב וד\"ר דנה אציל מהמחלקה לפסיכולוגיה).<p> המודל חוזה עבור כל קלט, את 5 האמוג'ים המובילים שצפויים להופיע איתו. מערכת אמוג'ים זו מתאימה לעיתים קרובות טוב עם הרגש או הרגש המתבטאים בטקסט.<p> אימנו את המודל על ידי איסוף מדגם גדול של ציוצים עבריים, שכל אחד מהם מכיל אחד מ -64 האמוג'ים למטה (לפחות 30,000 דוגמאות לכל אמוג'י, בסכום של יותר מ- 3.5M ציוצים). אז \"הסתרנו\" את האמוג'ים מהמודל, שנאלץ ללמוד לחזות את התשובה הנכונה. במהלך תהליך זה המודל למד לא רק להקצות אמוג'ים לציוצים אלא גם כיצד האמוג'ים השונים קשורים זה לזה.",
        "about02": "מעבר ליכולת לחזות את האימוג'י המתאים לטקסט הקלט הנתון, המודל עובד היטב כבסיס למשימות חיזוי רגשות אחרות, תוך שימוש בלמידת מעבר (Transfer learning). בדקנו זאת ע\"י קורפוס סיווג הסנטימנט העברי ששוחרר על ידי Amram et al. (2018)<sup>2</sup>. התוצאות המובילות הקודמות שדווחו על מערכי נתונים אלה השיגו דיוק תחזית רגשות של <span style=\"color: orange\">89.20%</span>. לאחר כיול סופי של  מודל ה-<i><b> Heמוג'י</b></i> המאומן מראש על נתוני הרגש, המודל המכוון משיג דיוק של <span style=\"color: green\">92.92%</span>.<p> פירוט קצת יותר טכני, המודל הוא ארכיטקטורה לעיבוד שפה טבעית, שכבת embedding ברמת token ואחריה שתי שכבות  bi-LSTM, שכבת attention, ולבסוף שכבת סיווג softmax.",
        "about03": "בזמן ה-fine-tuning, אנו מחליפים את שכבת הסיווג emoji softmax בסיווג softmax של סנטימנט חדש. לאחר מכן אנו מאמנים את השכבה החדשה תוך הקפאה של שאר הרשת, ואז מפרקים את הרשת בהדרגה, ומאמנים את כל השכבה (מהראשונה ועד האחרונה) בנפרד. לאחר מכן אנו מאמנים את כל הרשת מקצה לקצה.<p>אמנם יש לנו תכניות מדעיות משלנו לשימוש במודל, אך אנו מוצאים שימושים פוטנציאליים רבים לכך. כדי להקל על אחרים להשתמש במודל, אנו משחררים אותו כ-docker \uD83D\uDC0B image המורכב ממודל Keras פשוט לשימוש, וקוד לעיבוד מראש (בקרוב)."

    },
    "en": {
        "title": "***heMoji*** Predictor",
        "sub_title": "***heMoji*** will try to detect the sentiment, emotion and sarcasm of your Hebrew sentence and predict the correspond emoji for it",

        "sb_title": "***heMoji***",
        "sb_home_page": "Home",
        "sb_about_page": "About",

        "text_input": "Insert Hebrew sentence:",
        "examples_sents": "Or choose any example sentence below",

        "table_label": "Predicted emojis:",
        "table_emoji": "emoji",
        "table_prob": "prob",

        "page_about_title": "About ***heMoji***",
        "about01": "<p>The <i><b>heMoji</i></b> system predicts Emojis for Hebrew text.<p>It is about time to get some emoji predictions over Hebrew text! The <i><b>heMoji</i></b> system predicts emojis for Hebrew texts, and can be used as a basis for more targetted sentiment/emotion/sarcasm detection systems.<p><i><b>heMoji</i></b> is an adaptation of the Felbo et al (2017)<sup>1</sup> English system to Hebrew.<p>It was developed by Daniel Juravski at the Bar-Ilan natural language processing lab, as part of a larger project on automatic analysis of text in psychotherapy sessions, in order to gain insights on the psychotherapy process (the project is supervised by Prof. Yoav Goldberg from the computer science department and Dr. Dana Atzil from the Psychology department).<p>The model guesses, for each input, the top-5 emojis that are the most likely to appear with it. This set of emojis often correlates well with the sentiment or emotion that is expressed in the text.<p>We trained the model by collecting a large sample of Hebrew tweets, each of them containing one of the 64 emojis below (at least 30,000 examples for each emoji, totalling in more than 3.5M tweets). We then \"hid\" the emojis from the model, who had to learn to predict the correct answer. During this process, the model learned not only to assign emojis to tweets but also how the different emojis relate to each other.<p>",
        "about02": "Beyond the ability to predict the corresponding emoji for the given the input text, the model works well as the basis for other sentiment prediction tasks, using transfer learning.  We tested it on the Hebrew sentiment-classification corpus released by Amram et al. (2018)<sup>2</sup>. Previous best reported results on these datasets achieved sentiment prediction accuracy of <span style=\"color: orange\">89.20%</span>. After fine-tuning the pre-trained <i><b>heMoji</b></i> model on sentiment data, the fine-tuned model achieves an accuracy of <span style=\"color: green\">92.92%</span>.<p>To get more technical, the model is a (by now fairly standard) neural natural language processing architecture: a token-level embedding layer followed by two bi-LSTM layers, an attention layer, and a softmax classification layer.",
        "about03": "When fine-tuning, we replace the emoji softmax classification layer by a new sentiment softmax classifier. We then train the new layer while freezing the rest of the network, and then gradually unfreeze the network, fine-tuning the each layer (from first to last) individually. We then fine tune the entire network end-to-end.<p>While we have our own scientific plans for using the model, we imagine many potential uses for it. To make it easy for others to use the model, we release it as a dockerised \uD83D\uDC0B image which includes an easy-to-use pretrained Keras model and and pre-processing code (coming soon)."

    }

}

